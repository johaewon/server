ninja_required_version = 1.3
cxx = c++
nvcc = /usr/local/cuda-11.8/bin/nvcc

cflags = -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/home/cvlserver/Haewon/Research/egtr-main/model/custom_kernel -isystem /home/cvlserver/anaconda3/envs/haewon3/lib/python3.9/site-packages/torch/include -isystem /home/cvlserver/anaconda3/envs/haewon3/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /home/cvlserver/anaconda3/envs/haewon3/lib/python3.9/site-packages/torch/include/TH -isystem /home/cvlserver/anaconda3/envs/haewon3/lib/python3.9/site-packages/torch/include/THC -isystem /usr/local/cuda-11.8/include -isystem /home/cvlserver/anaconda3/envs/haewon3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -DWITH_CUDA=1
post_cflags = 
cuda_cflags = -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/home/cvlserver/Haewon/Research/egtr-main/model/custom_kernel -isystem /home/cvlserver/anaconda3/envs/haewon3/lib/python3.9/site-packages/torch/include -isystem /home/cvlserver/anaconda3/envs/haewon3/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /home/cvlserver/anaconda3/envs/haewon3/lib/python3.9/site-packages/torch/include/TH -isystem /home/cvlserver/anaconda3/envs/haewon3/lib/python3.9/site-packages/torch/include/THC -isystem /usr/local/cuda-11.8/include -isystem /home/cvlserver/anaconda3/envs/haewon3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -std=c++14
cuda_post_cflags = 
ldflags = -shared -L/home/cvlserver/anaconda3/envs/haewon3/lib/python3.9/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda-11.8/lib64 -lcudart

rule compile
  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out $post_cflags
  depfile = $out.d
  deps = gcc

rule cuda_compile
  depfile = $out.d
  deps = gcc
  command = $nvcc  $cuda_cflags -c $in -o $out $cuda_post_cflags

rule link
  command = $cxx $in $ldflags -o $out

build vision.o: compile /home/cvlserver/Haewon/Research/egtr-main/model/custom_kernel/vision.cpp
build ms_deform_attn_cpu.o: compile /home/cvlserver/Haewon/Research/egtr-main/model/custom_kernel/cpu/ms_deform_attn_cpu.cpp
build ms_deform_attn_cuda.cuda.o: cuda_compile /home/cvlserver/Haewon/Research/egtr-main/model/custom_kernel/cuda/ms_deform_attn_cuda.cu

build MultiScaleDeformableAttention.so: link vision.o ms_deform_attn_cpu.o ms_deform_attn_cuda.cuda.o

default MultiScaleDeformableAttention.so

